{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98e2b0f7",
   "metadata": {},
   "source": [
    "# System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3f5b1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIT_OUTLINE_SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert academic assistant tasked with parsing a university unit outline document and extracting key information into a structured JSON format.\n",
    "\n",
    "The input will be the raw text content of a unit outline. Your goal is to identify and extract the following details and structure them precisely as specified in the JSON schema below.\n",
    "\n",
    "**JSON Output Schema:**\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"unitInformation\": {{\n",
    "    \"unitCode\": \"string | null\",\n",
    "    \"unitName\": \"string | null\",\n",
    "    \"creditPoints\": \"integer | null\",\n",
    "    \"unitRationale\": \"string | null\",\n",
    "    \"prerequisites\": \"string | null\"\n",
    "  }},\n",
    "  \"learningOutcomes\": [\n",
    "    \"string\"\n",
    "  ],\n",
    "  \"assessments\": [\n",
    "    {{\n",
    "      \"taskName\": \"string\",\n",
    "      \"description\": \"string\",\n",
    "      \"dueWeek\": \"string | null\",\n",
    "      \"weightingPercent\": \"integer | null\",\n",
    "      \"learningOutcomesAssessed\": \"string | null\"\n",
    "    }}\n",
    "  ],\n",
    "  \"weeklySchedule\": [\n",
    "    {{\n",
    "      \"week\": \"string\",\n",
    "      \"contentTopic\": \"string\",\n",
    "      \"requiredReading\": \"string | null\"\n",
    "    }}\n",
    "  ],\n",
    "  \"requiredReadings\": [\n",
    "    \"string\"\n",
    "  ],\n",
    "  \"recommendedReadings\": [\n",
    "    \"string\"\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Instructions for Extraction:\n",
    "Unit Information: Locate Unit Code, Unit Name, Credit Points. Capture 'Unit Overview / Rationale' as unitRationale. Identify prerequisites.\n",
    "Learning Outcomes: Extract each learning outcome statement.\n",
    "Assessments: Each task as an object. Capture full task name, description, Due Week, Weighting % (number), and Learning Outcomes Assessed.\n",
    "weeklySchedule: Each week as an object. Capture Week, contentTopic, and requiredReading.\n",
    "Required and Recommended Readings: List full text for each.\n",
    "**Important Considerations for the LLM**:\n",
    "Pay close attention to headings and table structures.\n",
    "If information is missing, use null for string/integer fields, or an empty list [] for array fields.\n",
    "Do no change keys in the template given\n",
    "Ensure the output is ONLY the JSON object, starting with {{{{ and ending with }}}}. No explanations or conversational text before or after the JSON. \n",
    "Now, parse the following unit outline text:\n",
    "--- UNIT_OUTLINE_TEXT_START ---\n",
    "{outline_text}\n",
    "--- UNIT_OUTLINE_TEXT_END ---\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5912dd4",
   "metadata": {},
   "source": [
    "# Extrac Unit outline details to process following steps - output raw json with UO details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bab40704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 23:56:34,881 - __main__ - INFO - Initializing Ollama client for host: http://localhost:11434\n",
      "2025-06-09 23:56:34,896 - httpx - INFO - HTTP Request: GET http://localhost:11434/api/tags \"HTTP/1.1 200 OK\"\n",
      "2025-06-09 23:56:34,898 - __main__ - INFO - Ollama client connected to http://localhost:11434.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempting to parse: /home/sebas_dev_linux/projects/course_generator/data/UO/ICT312 Digital Forensic_Final.docx\n",
      "Using LLM Provider: ollama\n",
      "Ollama Host: http://localhost:11434, Model: mistral:latest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 23:57:22,074 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-06-09 23:57:22,075 - __main__ - INFO - Successfully parsed unit outline '/home/sebas_dev_linux/projects/course_generator/data/UO/ICT312 Digital Forensic_Final.docx' using ollama model mistral:latest.\n",
      "2025-06-09 23:57:22,075 - __main__ - INFO - Parsed outline saved to: ICT312 Digital Forensic_Final_parsed.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Successfully Parsed Outline Data (first few lines) ---\n",
      "{\n",
      "  \"unitInformation\": {\n",
      "    \"unitCode\": \"ICT312\",\n",
      "    \"unitName\": \"Digital Forensic\",\n",
      "    \"creditPoints\": 6,\n",
      "    \"unitRationale\": \"Course topics include principles of forensic analysis, forensics and the law, forensics on various types of infrastructure, and management of forensic methodologies, along with a variety of real-life case studies. Students will apply forensic methods in controlled environments and gain an understanding of the technical process of uncovering hidden data and other metadata that may reveal user behaviour.\",\n",
      "    \"prerequisites\": null\n",
      "  },\n",
      "  \"learningOutcomes\": [\n",
      "    \"On successful completion of this unit, students will be able to: Evaluate theories of digital forensics\",\n",
      "    \"Understand the structure of forensic evidence\",\n",
      "    \"Implement forensically sound digital security practices in the industry\",\n",
      "    \"Demonstrate competence in applying industry-standard forensic analysis techniques\",\n",
      "    \"Manage, research, and write comprehensive forensic reports and essay...\n",
      "----------------------------------------------------------\n",
      "Full parsed data saved to 'ICT312 Digital Forensic_Final_parsed.json'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Standard Libraries ---\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "import warnings # Added for managing warnings if libraries are missing\n",
    "\n",
    "# --- Third-Party Libraries ---\n",
    "# Make sure to install these: pip install python-docx ollama tenacity\n",
    "try:\n",
    "    from docx import Document\n",
    "    docx_available = True\n",
    "except ImportError:\n",
    "    warnings.warn(\"python-docx library not found. DOCX parsing will fail. `pip install python-docx`\")\n",
    "    docx_available = False\n",
    "\n",
    "try:\n",
    "    import pdfplumber \n",
    "    pdfplumber_available = True \n",
    "except ImportError: \n",
    "    warnings.warn(\"pdfplumber library not found. PDF parsing will fail. `pip install pdfplumber`\") \n",
    "    pdfplumber_available = False \n",
    "\n",
    "\n",
    "try:\n",
    "    import ollama\n",
    "    ollama_available = True\n",
    "except ImportError:\n",
    "    warnings.warn(\"ollama library not found. Ollama functionality disabled. `pip install ollama`\")\n",
    "    ollama_available = False\n",
    "\n",
    "try:\n",
    "    from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "    tenacity_available = True\n",
    "except ImportError:\n",
    "    warnings.warn(\"tenacity library not found. Retry functionality will not work. `pip install tenacity`\")\n",
    "    tenacity_available = False\n",
    "\n",
    "# --- Logger Setup ---\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- LLM Configuration (Global for this script) ---\n",
    "# These would typically be managed more dynamically as in your original script\n",
    "LLM_PROVIDER = \"ollama\" # Can be \"ollama\", \"openai\", \"gemini\"\n",
    "OLLAMA_HOST = \"http://localhost:11434\"\n",
    "OLLAMA_MODEL = \"mistral:latest\" # Or \"llama3.2:3b\", \"mistral:latest\", \"openthinker:7b \", \"\" - choose a capable model\n",
    "# Placeholder for other providers if you extend this script\n",
    "OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
    "GEMINI_MODEL = \"gemini-1.5-flash-latest\"\n",
    "\n",
    "\n",
    "PATH_UO = \"/home/sebas_dev_linux/projects/course_generator/data/UO/ICT312 Digital Forensic_Final.docx\"\n",
    "\n",
    "# Retry configuration (if tenacity is available)\n",
    "if tenacity_available:\n",
    "    LLM_MAX_RETRIES = 3\n",
    "    LLM_RETRY_WAIT_MIN = 2\n",
    "    LLM_RETRY_WAIT_MAX = 10\n",
    "\n",
    "    def log_retry_attempt(retry_state):\n",
    "        logger.warning(f\"LLM call attempt {retry_state.attempt_number} failed with {retry_state.outcome.exception()}, retrying...\")\n",
    "\n",
    "    retry_decorator = retry(\n",
    "        stop=stop_after_attempt(LLM_MAX_RETRIES),\n",
    "        wait=wait_exponential(min=LLM_RETRY_WAIT_MIN, max=LLM_RETRY_WAIT_MAX),\n",
    "        retry_error_callback=log_retry_attempt,\n",
    "    )\n",
    "else:\n",
    "    # Define a dummy decorator if tenacity is not available\n",
    "    def retry_decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            return func(*args, **kwargs) # Just call the function directly\n",
    "        return wrapper\n",
    "\n",
    "# Global LLM clients (initialize before use)\n",
    "client_ollama = None\n",
    "# client_openai = None # Placeholder\n",
    "# gemini_model_obj = None # Placeholder\n",
    "\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def extract_text_from_file(filepath): # Renamed for clarity\n",
    "    _, file_extension = os.path.splitext(filepath)\n",
    "    file_extension = file_extension.lower()\n",
    "\n",
    "    if file_extension == '.docx':\n",
    "        if not docx_available:\n",
    "            logger.error(\"python-docx library is not available. Cannot extract text from DOCX.\")\n",
    "            return None\n",
    "        try:\n",
    "            doc = Document(filepath)\n",
    "            full_text = []\n",
    "            for para in doc.paragraphs:\n",
    "                full_text.append(para.text)\n",
    "            for table in doc.tables:\n",
    "                for row in table.rows:\n",
    "                    row_text = [cell.text.strip() for cell in row.cells]\n",
    "                    full_text.append(\" | \".join(row_text))\n",
    "            return '\\n'.join(full_text)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading docx file {filepath}: {e}\", exc_info=True)\n",
    "            return None\n",
    "    elif file_extension == '.pdf':\n",
    "        if not pdfplumber_available:\n",
    "            logger.error(\"pdfplumber library is not available. Cannot extract text from PDF.\")\n",
    "            return None\n",
    "        try:\n",
    "            full_text = []\n",
    "            with pdfplumber.open(filepath) as pdf:\n",
    "                for page_num, page in enumerate(pdf.pages):\n",
    "                    logger.debug(f\"Extracting text from PDF page {page_num + 1}\")\n",
    "                    page_text = page.extract_text()\n",
    "                    if page_text:\n",
    "                        full_text.append(page_text)\n",
    "                    # You could also try extracting tables with page.extract_tables()\n",
    "                    # and format them if needed.\n",
    "            return '\\n'.join(full_text)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading PDF file {filepath}: {e}\", exc_info=True)\n",
    "            return None\n",
    "    elif file_extension == '.txt':\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                return f.read()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading TXT file {filepath}: {e}\", exc_info=True)\n",
    "            return None\n",
    "    else:\n",
    "        logger.error(f\"Unsupported file type: {file_extension}. Cannot extract text from {filepath}\")\n",
    "        return None\n",
    "\n",
    "def parse_llm_unit_outline_json(content: str, llm_provider_name: str):\n",
    "    if not isinstance(content, str) or not content.strip():\n",
    "        logger.warning(f\"Received empty/non-string content for unit outline from {llm_provider_name}.\")\n",
    "        return None\n",
    "    try:\n",
    "        content_cleaned = re.sub(r\"^```json\\s*|\\s*```$\", \"\", content.strip(), flags=re.MULTILINE)\n",
    "        json_start = content_cleaned.find(\"{\")\n",
    "        json_end = content_cleaned.rfind(\"}\") + 1\n",
    "        if json_start != -1 and json_end != 0:\n",
    "            json_str = content_cleaned[json_start:json_end]\n",
    "            data = json.loads(json_str)\n",
    "            # Optional: Add jsonschema validation here if desired\n",
    "            return data\n",
    "        else:\n",
    "            logger.warning(f\"Could not find JSON object in unit outline response from {llm_provider_name}: {content_cleaned}\")\n",
    "            return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.warning(f\"JSON Decode Error for unit outline ({llm_provider_name}): {e}\\nRaw Output:\\n{content_cleaned}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error parsing unit outline JSON from {llm_provider_name}: {e}\\nRaw Output:\\n{content_cleaned}\", exc_info=True)\n",
    "        return None\n",
    "\n",
    "@retry_decorator # Apply the retry decorator\n",
    "def call_ollama_to_parse_outline(prompt_with_outline_text):\n",
    "    global client_ollama # Uses the globally initialized client\n",
    "    if not ollama_available or client_ollama is None:\n",
    "        logger.warning(\"Ollama client not available or not initialized for outline parsing.\")\n",
    "        # To make retry work properly, we should raise an error that tenacity can catch\n",
    "        raise ConnectionError(\"Ollama client not available or not initialized.\")\n",
    "\n",
    "    logger.debug(f\"Attempting Ollama call for unit outline parsing (Model: {OLLAMA_MODEL} Host: {OLLAMA_HOST})...\")\n",
    "    try:\n",
    "        response = client_ollama.chat(\n",
    "            model=OLLAMA_MODEL,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt_with_outline_text}],\n",
    "            options={\"temperature\": 0.00}, # Low temp for factual, top_p for some diversity if needed\n",
    "            format=\"json\",\n",
    "        )\n",
    "        if not response or 'message' not in response or 'content' not in response['message'] or not response['message']['content']:\n",
    "            logger.warning(f\"Ollama returned empty/invalid response for outline: {response}\")\n",
    "            raise ValueError(\"Ollama returned empty or invalid response for outline\")\n",
    "        content = response['message']['content']\n",
    "        return parse_llm_unit_outline_json(content, \"ollama\")\n",
    "    except Exception as e:\n",
    "        # Log specific connection errors differently for clarity\n",
    "        if isinstance(e, (ollama.ResponseError, ollama.RequestError)) and (\"Connection refused\" in str(e) or \"Max retries exceeded with url\" in str(e)):\n",
    "             logger.error(f\"Ollama connection error for outline parsing to {OLLAMA_HOST}: {e}.\")\n",
    "        elif isinstance(e, ValueError) and \"Ollama returned empty\" in str(e):\n",
    "            pass # Already logged, just re-raise for tenacity\n",
    "        else:\n",
    "            logger.error(f\"Ollama API call for outline parsing failed: {e}\", exc_info=False)\n",
    "        raise # Reraise to trigger tenacity retry if applicable\n",
    "\n",
    "# --- Main Parsing Orchestration Function ---\n",
    "def parse_unit_outline_with_llm(outline_filepath, system_prompt_template):\n",
    "    global LLM_PROVIDER, client_ollama # Use global provider and client\n",
    "\n",
    "    # Ensure client is initialized for the selected provider\n",
    "    if LLM_PROVIDER == \"ollama\" and ollama_available:\n",
    "        if client_ollama is None:\n",
    "            try:\n",
    "                logger.info(f\"Initializing Ollama client for host: {OLLAMA_HOST}\")\n",
    "                client_ollama = ollama.Client(host=OLLAMA_HOST)\n",
    "                client_ollama.list() # Test connection\n",
    "                logger.info(f\"Ollama client connected to {OLLAMA_HOST}.\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to initialize Ollama client to {OLLAMA_HOST}: {e}. Cannot parse outline.\")\n",
    "                return None\n",
    "    # Add elif for openai, gemini if you implement them\n",
    "\n",
    "    outline_text = extract_text_from_file(outline_filepath)\n",
    "    if not outline_text:\n",
    "        logger.error(f\"Failed to extract text from unit outline: {outline_filepath}\")\n",
    "        return None\n",
    "\n",
    "    prompt_for_llm = system_prompt_template.format(outline_text=outline_text)\n",
    "    # logger.debug(f\"Unit Outline Parsing Prompt (first 500 chars):\\n{prompt_for_llm[:500]}...\")\n",
    "\n",
    "    parsed_data = None\n",
    "    try:\n",
    "        if LLM_PROVIDER == \"ollama\" and ollama_available:\n",
    "            parsed_data = call_ollama_to_parse_outline(prompt_for_llm)\n",
    "        # elif LLM_PROVIDER == \"openai\" and openai_available:\n",
    "        #     # parsed_data = call_openai_to_parse_outline(prompt_for_llm) # Implement this\n",
    "        #     logger.warning(\"OpenAI outline parsing not yet fully implemented in this example.\")\n",
    "        # elif LLM_PROVIDER == \"gemini\" and gemini_available:\n",
    "        #     # parsed_data = call_gemini_to_parse_outline(prompt_for_llm) # Implement this\n",
    "        #     logger.warning(\"Gemini outline parsing not yet fully implemented in this example.\")\n",
    "        else:\n",
    "            logger.error(f\"Unsupported or unavailable LLM provider for outline parsing: {LLM_PROVIDER}\")\n",
    "            return None\n",
    "\n",
    "        if parsed_data:\n",
    "            logger.info(f\"Successfully parsed unit outline '{outline_filepath}' using {LLM_PROVIDER} model {OLLAMA_MODEL if LLM_PROVIDER == 'ollama' else 'N/A'}.\")\n",
    "            output_json_filename = os.path.splitext(os.path.basename(outline_filepath))[0] + \"_parsed.json\"\n",
    "            # output_json_path = os.path.join(os.getcwd(), output_json_filename) # Save in current dir for Jupyter\n",
    "            try:\n",
    "                with open(output_json_filename, 'w') as f:\n",
    "                    json.dump(parsed_data, f, indent=2)\n",
    "                logger.info(f\"Parsed outline saved to: {output_json_filename}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Could not save parsed JSON to {output_json_filename}: {e}\")\n",
    "            return parsed_data\n",
    "        else:\n",
    "            logger.error(f\"Failed to parse unit outline '{outline_filepath}' using {LLM_PROVIDER} after retries.\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during unit outline parsing with {LLM_PROVIDER}: {e}\", exc_info=True)\n",
    "        return None\n",
    "\n",
    "# --- Example Usage (Jupyter cell execution) ---\n",
    "if __name__ == '__main__': # This block will run if you execute the script directly\n",
    "                           # Or if you run this cell in Jupyter after the first one.\n",
    "\n",
    "    # Ensure the prompt template is defined (it should be if Cell 1 was run)\n",
    "    if 'UNIT_OUTLINE_SYSTEM_PROMPT_TEMPLATE' not in globals():\n",
    "        print(\"ERROR: UNIT_OUTLINE_SYSTEM_PROMPT_TEMPLATE not defined. Please run the first cell.\")\n",
    "    else:\n",
    "        # Create a dummy DOCX file for testing if it doesn't exist\n",
    "        # IMPORTANT: Replace this with the actual path to your 'ICT312 Digital Forensic_Final.docx'\n",
    "        test_outline_filename = PATH_UO # âœ…ðŸ”´ Make sure path is correct\n",
    "\n",
    "        # if not os.path.exists(test_outline_filename) and docx_available:\n",
    "        #     print(f\"Test file '{test_outline_filename}' not found. Creating a dummy one.\")\n",
    "        #     doc = Document()\n",
    "        #     doc.add_heading('SECTION 1 â€“ GENERAL INFORMATION', level=1)\n",
    "        #     doc.add_paragraph('1.0 Name of School\\nSchool of Business')\n",
    "        #     doc.add_paragraph('1.1 Unit Details\\nUnit Code\\tICT000\\nUnit Name\\tDummy Unit\\nCredit Points\\t6')\n",
    "        #     doc.add_paragraph('SECTION 2 â€“ ACADEMIC INFORMATION')\n",
    "        #     doc.add_paragraph('2.0 Learning Outcomes\\n1. Learn things.\\n2. Do stuff.')\n",
    "        #     doc.add_paragraph('2.2 Weekly Schedule\\nWeek & Date\\tContent/Topic(s)\\tRequired Reading\\nWeek 1\\tIntro to Dummy\\tChapter 1')\n",
    "        #     doc.save(test_outline_filename)\n",
    "        #     print(f\"Dummy file '{test_outline_filename}' created. Please replace with your actual file for real testing.\")\n",
    "        # elif not docx_available:\n",
    "        #     print(f\"Cannot create dummy DOCX because python-docx is not available.\")\n",
    "\n",
    "\n",
    "        if os.path.exists(test_outline_filename):\n",
    "            print(f\"\\nAttempting to parse: {test_outline_filename}\")\n",
    "            print(f\"Using LLM Provider: {LLM_PROVIDER}\")\n",
    "            if LLM_PROVIDER == \"ollama\":\n",
    "                print(f\"Ollama Host: {OLLAMA_HOST}, Model: {OLLAMA_MODEL}\")\n",
    "\n",
    "            # Call the main parsing function\n",
    "            parsed_data = parse_unit_outline_with_llm(test_outline_filename, UNIT_OUTLINE_SYSTEM_PROMPT_TEMPLATE)\n",
    "\n",
    "            if parsed_data:\n",
    "                print(\"\\n--- Successfully Parsed Outline Data (first few lines) ---\")\n",
    "                # Print a snippet to avoid flooding output if very large\n",
    "                parsed_data_str = json.dumps(parsed_data, indent=2)\n",
    "                print(parsed_data_str[:1000] + (\"...\" if len(parsed_data_str) > 1000 else \"\"))\n",
    "                print(\"----------------------------------------------------------\")\n",
    "                print(f\"Full parsed data saved to '{os.path.splitext(os.path.basename(test_outline_filename))[0] + '_parsed.json'}'\")\n",
    "            else:\n",
    "                print(f\"\\nFailed to parse {test_outline_filename}.\")\n",
    "        else:\n",
    "            print(f\"\\nTest outline file '{test_outline_filename}' not found and could not be created. Please provide the file.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
